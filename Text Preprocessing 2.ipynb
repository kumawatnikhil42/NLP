{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165d4ae6-5303-425e-8c21-bf8a1390ba46",
   "metadata": {},
   "source": [
    "# Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05bf4ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a79bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6022b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize , sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed40af63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'visit', 'delhi', '!']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = \"I am going to visit delhi!\"\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc4c52a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2 = 'I have a Ph.D. in A.I.'\n",
    "sent3 = \"We 're here to help! mail us at nk@gmail.com\"\n",
    "sent4 = 'A Skm ride cost $10.50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3428020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D.', 'in', 'A.I', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "714b30a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"We 're here to help!\", 'mail us at nk@gmail.com']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sent3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2354861-ba2c-4d8e-b57c-1c7925ce123f",
   "metadata": {},
   "source": [
    "# Stemming and Lemmitization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018eac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d379c909-6a50-4c86-afb4-24d9f573b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8787b809-80cd-4264-aaad-be161a35f1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=\"walk walking walks walked\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec915dc8-0cfa-42d8-827f-5f0e9620762d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "He                  He                  \n",
      "was                 be                  \n",
      "running             run                 \n",
      "and                 and                 \n",
      "eating              eat                 \n",
      "at                  at                  \n",
      "same                same                \n",
      "time                time                \n",
      "He                  He                  \n",
      "has                 have                \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "swimming            swim                \n",
      "after               after               \n",
      "playing             play                \n",
      "long                long                \n",
      "hours               hours               \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "sun                 sun                 \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet=WordNetLemmatizer()\n",
    "\n",
    "sentence=\"He was running and eating at same time. He has bad habit of swimming after playing long hours in the sun.\"\n",
    "punctuations=\"?:!.,:\"\n",
    "sentence_words=nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "print(\"{0:20}{1:20}\" .format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print('{0:20}{1:20}' .format(word,wordnet.lemmatize(word,pos='v')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825dcd1-b65c-48f2-9485-6e4c41ef684a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
